<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>src.text.outlier_detection.space.embedding_space API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>src.text.outlier_detection.space.embedding_space</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="src.text.outlier_detection.space.embedding_space.EmbeddingSpace"><code class="flex name class">
<span>class <span class="ident">EmbeddingSpace</span></span>
<span>(</span><span>model: text.Embedding.LLM.huggingmodel.HuggingModel,<br>train_size: int = -1,<br>test_size: int = -1)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class EmbeddingSpace(Space):

    @property
    def name(self):
        return name

    def transform_dataset(self, dataset: Dataset, use_cached: bool, inlier_label, mask: Optional[Tensor]) -&gt; PreparedData:
        if use_cached:
            prepared_data = self._use_cached(dataset, inlier_label)
        else:
            prepared_data = self._create_data(dataset, inlier_label)
        if mask is None:
            return prepared_data

        # Apply the mask to the data
        mask = mask.to(prepared_data.x_train.device)
        assert mask.dtype == torch.int, f&#34;Mask should be of type int, but got {mask.dtype}&#34;
        assert len(mask.shape) == 1, f&#34;Mask should be 1D, but got {mask.shape}&#34;
        bool_mask = mask == 1

        prepared_data.x_train = prepared_data.x_train[:, bool_mask]
        prepared_data.x_test = prepared_data.x_test[:, bool_mask]

        return prepared_data

    def _use_cached(self, dataset: Dataset, inlier_label) -&gt; PreparedData:
        dataset_embedder = DatasetEmbedder(dataset, self.model)

        x_train, y_train = dataset_embedder.embed(train=True, samples=self.train_size,
                                                              labels=[inlier_label])

        x_test, y_test = dataset_embedder.embed(train=False, samples=self.test_size)

        return PreparedData(x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test, space=name, inlier_labels=[inlier_label])

    def _create_data(self, dataset: Dataset, inlier_label) -&gt; PreparedData:
        # Get tokenized data and corresponding labels
        token_space = TokenSpace(model=self.model, train_size=self.train_size, test_size=self.test_size)
        #token_data = token_space.transform_dataset(dataset, use_cached=False, inlier_label=inlier_label)

        x_train, y_train, x_test, y_test = token_space.get_tokenized(dataset, inlier_label)

        x_train = token_space.embed_tokenized(x_train)
        x_test = token_space.embed_tokenized(x_test)
        return PreparedData(x_train=x_train,
                            y_train=y_train,
                            x_test=x_test,
                            y_test=y_test,
                            space=name,
                            inlier_labels=[inlier_label])

    def __prepare_embedding(self, tokenized: Tensor) -&gt; Tensor:
        embedding_func = self.model.get_embedding_fun(batch_first=True)
        embedded = embedding_func(tokenized)
        #means = embedded.mean(1, keepdim=True)
        #stds = embedded.std(1, keepdim=True)
        #standardized = (embedded - means) / stds
        #normalized = torch.nn.functional.normalize(standardized, p=2, dim=1)
        #normalized = torch.nn.functional.normalize(embedded, p=2, dim=1)
        #return normalized
        return embedded</code></pre>
</details>
<div class="desc"><p>This class represents the space that the outlier detection models
should operate in.</p>
<p>Initializes the Space object.
:param model: The model to use to generate the space.
:param train_size: The size of the training set.
:param test_size: The size of the test set.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>text.outlier_detection.space.space.Space</li>
<li>abc.ABC</li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="src.text.outlier_detection.space.embedding_space.EmbeddingSpace.name"><code class="name">prop <span class="ident">name</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def name(self):
    return name</code></pre>
</details>
<div class="desc"><p>Returns the name of the space.</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="src.text.outlier_detection.space.embedding_space.EmbeddingSpace.transform_dataset"><code class="name flex">
<span>def <span class="ident">transform_dataset</span></span>(<span>self,<br>dataset: text.dataset.dataset.Dataset,<br>use_cached: bool,<br>inlier_label,<br>mask: torch.Tensor | None) ‑> text.outlier_detection.space.prepared_data.PreparedData</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transform_dataset(self, dataset: Dataset, use_cached: bool, inlier_label, mask: Optional[Tensor]) -&gt; PreparedData:
    if use_cached:
        prepared_data = self._use_cached(dataset, inlier_label)
    else:
        prepared_data = self._create_data(dataset, inlier_label)
    if mask is None:
        return prepared_data

    # Apply the mask to the data
    mask = mask.to(prepared_data.x_train.device)
    assert mask.dtype == torch.int, f&#34;Mask should be of type int, but got {mask.dtype}&#34;
    assert len(mask.shape) == 1, f&#34;Mask should be 1D, but got {mask.shape}&#34;
    bool_mask = mask == 1

    prepared_data.x_train = prepared_data.x_train[:, bool_mask]
    prepared_data.x_test = prepared_data.x_test[:, bool_mask]

    return prepared_data</code></pre>
</details>
<div class="desc"><p>Prepares the data for the outlier detection model.
:param dataset: The dataset to prepare the data from.
:param use_cached: Whether to use cached data.
If True, the data will be loaded from cached files if it exists or
cached files will be created.
If False, the data will be created from scratch and not cached.
:param inlier_label: The label of the inliers.
:param mask: The mask to apply to the data. That is, the projection
into a subspace.
:return: The PreparedData object that contains the training and
testing data, projected in this space and then transformed into
the embedding space.
testing data.</p></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="src.text.outlier_detection.space" href="index.html">src.text.outlier_detection.space</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="src.text.outlier_detection.space.embedding_space.EmbeddingSpace" href="#src.text.outlier_detection.space.embedding_space.EmbeddingSpace">EmbeddingSpace</a></code></h4>
<ul class="">
<li><code><a title="src.text.outlier_detection.space.embedding_space.EmbeddingSpace.name" href="#src.text.outlier_detection.space.embedding_space.EmbeddingSpace.name">name</a></code></li>
<li><code><a title="src.text.outlier_detection.space.embedding_space.EmbeddingSpace.transform_dataset" href="#src.text.outlier_detection.space.embedding_space.EmbeddingSpace.transform_dataset">transform_dataset</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
