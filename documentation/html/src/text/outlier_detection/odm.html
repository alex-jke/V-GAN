<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>src.text.outlier_detection.odm API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>src.text.outlier_detection.odm</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="src.text.outlier_detection.odm.OutlierDetectionModel"><code class="flex name class">
<span>class <span class="ident">OutlierDetectionModel</span></span>
<span>(</span><span>dataset: text.dataset.dataset.Dataset,<br>space: text.outlier_detection.space.space.Space,<br>base_method: Type[pyod.models.base.BaseDetector],<br>inlier_label: int | None = None,<br>use_cached: bool = False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class OutlierDetectionModel(ABC):
    &#34;&#34;&#34;
    Abstract class for outlier detection models. Specifically for one-class classification.
    &#34;&#34;&#34;
    def __init__(self, dataset: Dataset, space: Space, base_method: Type[BaseDetector], inlier_label: int | None = None, use_cached: bool = False):
        self.dataset = dataset
        self.use_cached = use_cached
        self.inlier_label = inlier_label
        if inlier_label is None:
            self.inlier_label = self.dataset.get_possible_labels()[0]
        self.ui = cli.get()
        self.method_column = METHOD_COL
        self._data: PreparedData | None = None
        self.space: Space = space
        self.device = self.space.model.device
        self.base_method: Type[BaseDetector] = base_method

    @abstractmethod
    def get_space_type(self) -&gt; SpaceType:
        pass

    @abstractmethod
    def _train(self):
        pass

    @property
    def data(self) -&gt; PreparedData:
        if self._data is None:
            self._data = self.space.transform_dataset(self.dataset, self.use_cached, self.inlier_label, None)
            assert len(self.data.y_train.unique()) == 1 and int(self._data.y_train.unique()) == self.inlier_label, \
                f&#34;Training data contains other data, than just the inlier data. Expected {self.inlier_label}, got {self._data.y_train.unique()}&#34;
        return self._data

    def train(self):
        self._start_timer()
        self._train()

    def predict(self):
        self._predict()
        self._stop_timer()

    @abstractmethod
    def _predict(self):
        pass

    @abstractmethod
    def _get_name(self) -&gt; str:
        pass

    @abstractmethod
    def _get_predictions(self) -&gt; List[float]:
        pass

    def get_space(self) -&gt; str:
        return self.space.name

    @property
    def x_train(self) -&gt; Tensor:
        if self.data is None:
            raise ValueError(not_initizalied_error_msg)
        return self.data.x_train

    @property
    def y_train(self) -&gt; Tensor:
        if self.data is None:
            raise ValueError(not_initizalied_error_msg)
        return self.data.y_train

    @property
    def x_test(self) -&gt; Tensor:
        if self.data is None:
            raise ValueError(not_initizalied_error_msg)
        return self.data.x_test

    @property
    def y_test(self) -&gt; Tensor:
        if self.data is None:
            raise ValueError(not_initizalied_error_msg)
        return self.data.y_test

    def _start_timer(self):
        self.start_time = time()

    def _stop_timer(self):
        self.time_elapsed = time() - self.start_time

    def evaluate(self, output_path: Path = None)-&gt; (pd.DataFrame, pd.DataFrame):
        &#34;&#34;&#34;
        Evaluate the performance of a predictive model against a labeled test dataset.

        This method computes various evaluation metrics for the model including
         ROC AUC (Area Under the Curve), PRAUC, F1 and other relevant statistics such
        as percentages of inliers and outliers as well as confusion matrix components.
        Results and metrics are stored as DataFrames, and performance details can be printed
        to the console.

        Parameters:
            output_path (Path): The path where evaluation results can potentially
                be saved. This is not used in this implementation. It is included
                to allow subclasses to save extra results to a file.

        Returns:
            A pair of:
                pd.DataFrame: A DataFrame summarizing the evaluation metrics including
                    model accuracy, precision, recall, AUC, inliers and outliers percentages,
                    confusion matrix values, and other associated data.
                pd.DataFrame: A DataFrame containing common parameters used in the evaluation
                    such as the dataset name, model name, inlier label, and other relevant
                    information.
        &#34;&#34;&#34;
        # Get predicted and actual labels
        decision_function_scores = self._get_predictions()
        y_test = [0 if x == self.inlier_label else 1 for x in self.y_test]

        # Calculate AUC
        common_len = min(len(decision_function_scores), len(y_test))
        if common_len &lt; len(decision_function_scores) or common_len &lt; len(y_test): #todo: check if this is causing problems
            print(f&#34;Warning: Predicted ({len(decision_function_scores)}) and actual labels ({len(y_test)}) have different lengths. Trimming to common length: {common_len}.&#34;)
            decision_function_scores = decision_function_scores[:common_len]
            y_test = y_test[:common_len]
        try:
            auc = roc_auc_score(y_true=y_test, y_score=decision_function_scores)
        except ValueError as e:
            print(e)
            raise e
        prauc = average_precision_score(y_test, decision_function_scores)
        f1 = f1_score(y_test, (decision_function_scores &gt; np.quantile(decision_function_scores, .80)) * 1)


        # Calculate percentage of inliers and outliers
        percentage_outlier = sum(y_test) / len(y_test) * 100
        percentage_inlier = 100 - percentage_outlier

        self.results = pd.DataFrame({
            &#34;actual&#34;: y_test,
            &#34;predicted&#34;: decision_function_scores,
        })

        self.metrics = pd.DataFrame({
            self.method_column: [self._get_name()],
            SPACE_COL: [self.get_space()],
            AUC_COL: [auc],
            PRAUC_COL: [prauc],
            F1_COL: [f1],
            TIME_TAKEN_COL: [self.time_elapsed],
            BASE_COL: [self.base_method.__name__],
            #SPACE_TYPE_COL: [self.get_space_type()]
        })

        self.common_parameters = pd.DataFrame({
            PERCENTAGE_INLIER_COL : [percentage_inlier],
            PERCENTAGE_OUTLIER_COL : [percentage_outlier],
            TOTAL_TEST_SAMPLES_COL : [len(y_test)],
            TOTAL_TRAIN_SAMPLES_COL : [len(self.x_train)],
            INLIER_LABEL_COL : [self.inlier_label],
            OUTLIER_LABEL_COL : str([label for label in self.dataset.get_possible_labels() if label != self.inlier_label]),
            MODEL_COL : [self.space.model.model_name],
            DATASET_COL : [self.dataset.name],
        })

        return self.metrics, self.common_parameters</code></pre>
</details>
<div class="desc"><p>Abstract class for outlier detection models. Specifically for one-class classification.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="src.text.outlier_detection.odm.OutlierDetectionModel.data"><code class="name">prop <span class="ident">data</span> : text.outlier_detection.space.prepared_data.PreparedData</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def data(self) -&gt; PreparedData:
    if self._data is None:
        self._data = self.space.transform_dataset(self.dataset, self.use_cached, self.inlier_label, None)
        assert len(self.data.y_train.unique()) == 1 and int(self._data.y_train.unique()) == self.inlier_label, \
            f&#34;Training data contains other data, than just the inlier data. Expected {self.inlier_label}, got {self._data.y_train.unique()}&#34;
    return self._data</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="src.text.outlier_detection.odm.OutlierDetectionModel.x_test"><code class="name">prop <span class="ident">x_test</span> : torch.Tensor</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def x_test(self) -&gt; Tensor:
    if self.data is None:
        raise ValueError(not_initizalied_error_msg)
    return self.data.x_test</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="src.text.outlier_detection.odm.OutlierDetectionModel.x_train"><code class="name">prop <span class="ident">x_train</span> : torch.Tensor</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def x_train(self) -&gt; Tensor:
    if self.data is None:
        raise ValueError(not_initizalied_error_msg)
    return self.data.x_train</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="src.text.outlier_detection.odm.OutlierDetectionModel.y_test"><code class="name">prop <span class="ident">y_test</span> : torch.Tensor</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def y_test(self) -&gt; Tensor:
    if self.data is None:
        raise ValueError(not_initizalied_error_msg)
    return self.data.y_test</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="src.text.outlier_detection.odm.OutlierDetectionModel.y_train"><code class="name">prop <span class="ident">y_train</span> : torch.Tensor</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def y_train(self) -&gt; Tensor:
    if self.data is None:
        raise ValueError(not_initizalied_error_msg)
    return self.data.y_train</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="src.text.outlier_detection.odm.OutlierDetectionModel.evaluate"><code class="name flex">
<span>def <span class="ident">evaluate</span></span>(<span>self, output_path: pathlib.Path = None) ‑> (<class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.frame.DataFrame'>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def evaluate(self, output_path: Path = None)-&gt; (pd.DataFrame, pd.DataFrame):
    &#34;&#34;&#34;
    Evaluate the performance of a predictive model against a labeled test dataset.

    This method computes various evaluation metrics for the model including
     ROC AUC (Area Under the Curve), PRAUC, F1 and other relevant statistics such
    as percentages of inliers and outliers as well as confusion matrix components.
    Results and metrics are stored as DataFrames, and performance details can be printed
    to the console.

    Parameters:
        output_path (Path): The path where evaluation results can potentially
            be saved. This is not used in this implementation. It is included
            to allow subclasses to save extra results to a file.

    Returns:
        A pair of:
            pd.DataFrame: A DataFrame summarizing the evaluation metrics including
                model accuracy, precision, recall, AUC, inliers and outliers percentages,
                confusion matrix values, and other associated data.
            pd.DataFrame: A DataFrame containing common parameters used in the evaluation
                such as the dataset name, model name, inlier label, and other relevant
                information.
    &#34;&#34;&#34;
    # Get predicted and actual labels
    decision_function_scores = self._get_predictions()
    y_test = [0 if x == self.inlier_label else 1 for x in self.y_test]

    # Calculate AUC
    common_len = min(len(decision_function_scores), len(y_test))
    if common_len &lt; len(decision_function_scores) or common_len &lt; len(y_test): #todo: check if this is causing problems
        print(f&#34;Warning: Predicted ({len(decision_function_scores)}) and actual labels ({len(y_test)}) have different lengths. Trimming to common length: {common_len}.&#34;)
        decision_function_scores = decision_function_scores[:common_len]
        y_test = y_test[:common_len]
    try:
        auc = roc_auc_score(y_true=y_test, y_score=decision_function_scores)
    except ValueError as e:
        print(e)
        raise e
    prauc = average_precision_score(y_test, decision_function_scores)
    f1 = f1_score(y_test, (decision_function_scores &gt; np.quantile(decision_function_scores, .80)) * 1)


    # Calculate percentage of inliers and outliers
    percentage_outlier = sum(y_test) / len(y_test) * 100
    percentage_inlier = 100 - percentage_outlier

    self.results = pd.DataFrame({
        &#34;actual&#34;: y_test,
        &#34;predicted&#34;: decision_function_scores,
    })

    self.metrics = pd.DataFrame({
        self.method_column: [self._get_name()],
        SPACE_COL: [self.get_space()],
        AUC_COL: [auc],
        PRAUC_COL: [prauc],
        F1_COL: [f1],
        TIME_TAKEN_COL: [self.time_elapsed],
        BASE_COL: [self.base_method.__name__],
        #SPACE_TYPE_COL: [self.get_space_type()]
    })

    self.common_parameters = pd.DataFrame({
        PERCENTAGE_INLIER_COL : [percentage_inlier],
        PERCENTAGE_OUTLIER_COL : [percentage_outlier],
        TOTAL_TEST_SAMPLES_COL : [len(y_test)],
        TOTAL_TRAIN_SAMPLES_COL : [len(self.x_train)],
        INLIER_LABEL_COL : [self.inlier_label],
        OUTLIER_LABEL_COL : str([label for label in self.dataset.get_possible_labels() if label != self.inlier_label]),
        MODEL_COL : [self.space.model.model_name],
        DATASET_COL : [self.dataset.name],
    })

    return self.metrics, self.common_parameters</code></pre>
</details>
<div class="desc"><p>Evaluate the performance of a predictive model against a labeled test dataset.</p>
<p>This method computes various evaluation metrics for the model including
ROC AUC (Area Under the Curve), PRAUC, F1 and other relevant statistics such
as percentages of inliers and outliers as well as confusion matrix components.
Results and metrics are stored as DataFrames, and performance details can be printed
to the console.</p>
<h2 id="parameters">Parameters</h2>
<p>output_path (Path): The path where evaluation results can potentially
be saved. This is not used in this implementation. It is included
to allow subclasses to save extra results to a file.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt>A pair of:</dt>
<dt><code>
pd.DataFrame</code></dt>
<dd>A DataFrame summarizing the evaluation metrics including
model accuracy, precision, recall, AUC, inliers and outliers percentages,
confusion matrix values, and other associated data.
pd.DataFrame: A DataFrame containing common parameters used in the evaluation
such as the dataset name, model name, inlier label, and other relevant
information.</dd>
</dl></div>
</dd>
<dt id="src.text.outlier_detection.odm.OutlierDetectionModel.get_space"><code class="name flex">
<span>def <span class="ident">get_space</span></span>(<span>self) ‑> str</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_space(self) -&gt; str:
    return self.space.name</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="src.text.outlier_detection.odm.OutlierDetectionModel.get_space_type"><code class="name flex">
<span>def <span class="ident">get_space_type</span></span>(<span>self) ‑> text.outlier_detection.space_type.SpaceType</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def get_space_type(self) -&gt; SpaceType:
    pass</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="src.text.outlier_detection.odm.OutlierDetectionModel.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(self):
    self._predict()
    self._stop_timer()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="src.text.outlier_detection.odm.OutlierDetectionModel.train"><code class="name flex">
<span>def <span class="ident">train</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train(self):
    self._start_timer()
    self._train()</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="src.text.outlier_detection" href="index.html">src.text.outlier_detection</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="src.text.outlier_detection.odm.OutlierDetectionModel" href="#src.text.outlier_detection.odm.OutlierDetectionModel">OutlierDetectionModel</a></code></h4>
<ul class="two-column">
<li><code><a title="src.text.outlier_detection.odm.OutlierDetectionModel.data" href="#src.text.outlier_detection.odm.OutlierDetectionModel.data">data</a></code></li>
<li><code><a title="src.text.outlier_detection.odm.OutlierDetectionModel.evaluate" href="#src.text.outlier_detection.odm.OutlierDetectionModel.evaluate">evaluate</a></code></li>
<li><code><a title="src.text.outlier_detection.odm.OutlierDetectionModel.get_space" href="#src.text.outlier_detection.odm.OutlierDetectionModel.get_space">get_space</a></code></li>
<li><code><a title="src.text.outlier_detection.odm.OutlierDetectionModel.get_space_type" href="#src.text.outlier_detection.odm.OutlierDetectionModel.get_space_type">get_space_type</a></code></li>
<li><code><a title="src.text.outlier_detection.odm.OutlierDetectionModel.predict" href="#src.text.outlier_detection.odm.OutlierDetectionModel.predict">predict</a></code></li>
<li><code><a title="src.text.outlier_detection.odm.OutlierDetectionModel.train" href="#src.text.outlier_detection.odm.OutlierDetectionModel.train">train</a></code></li>
<li><code><a title="src.text.outlier_detection.odm.OutlierDetectionModel.x_test" href="#src.text.outlier_detection.odm.OutlierDetectionModel.x_test">x_test</a></code></li>
<li><code><a title="src.text.outlier_detection.odm.OutlierDetectionModel.x_train" href="#src.text.outlier_detection.odm.OutlierDetectionModel.x_train">x_train</a></code></li>
<li><code><a title="src.text.outlier_detection.odm.OutlierDetectionModel.y_test" href="#src.text.outlier_detection.odm.OutlierDetectionModel.y_test">y_test</a></code></li>
<li><code><a title="src.text.outlier_detection.odm.OutlierDetectionModel.y_train" href="#src.text.outlier_detection.odm.OutlierDetectionModel.y_train">y_train</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
